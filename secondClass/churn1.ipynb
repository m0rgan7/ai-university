import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

df = pd.read_csv('churn_dataset.csv')

# Visualiza as primeiras linhas
df.head()

# Features (variáveis independentes)
X = df[['idade', 'tempo_contrato', 'uso_mensal', 'suporte_chamados']]

# Variável alvo (0 = manteve, 1 = cancelou)
y = df['cancelou']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

k_values = [1, 3, 5, 7, 9]
accuracies = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    accuracies.append(acc)
    print(f'Acurácia com k={k}: {acc:.2f}')

plt.plot(k_values, accuracies, marker='o')
plt.title('Acurácia vs Valor de k')
plt.xlabel('k')
plt.ylabel('Acurácia')
plt.grid(True)
plt.show()

# Questões para reflexão

- 1. Qual valor de k trouxe a melhor acurácia?

O valor de k que trouxe a melhor acurácia foi k = X, com uma acurácia de Y%.

- 2. O modelo errou mais quando k era pequeno ou grande?

O modelo errou mais quando k era pequeno/grande, porque...

- 3. Por que mudar o parâmetro k altera os resultados?

O valor de k influencia quantos "vizinhos" o algoritmo considera. Um valor muito pequeno pode causar overfitting (muito sensível ao ruído), e um valor muito alto pode causar underfitting (decisões genéricas demais).
# Previsões
y_pred = knn.predict(X_test)

# Acurácia
acc = accuracy_score(y_test, y_pred)
print(f'Acurácia com k=5: {acc:.2f}')
